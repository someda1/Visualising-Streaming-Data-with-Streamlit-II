# -*- coding: utf-8 -*-
"""Visualising Streaming Data with Streamlit II-simeon omeda.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EQHYVX9KEpSkUs9IiRMJBNXeJXwNGzVJ

## `Visualising Streaming Data with Streamlit II-simeon omeda`
"""

!pip install pandas
!pip install praw
!pip install streamlit
!pip install matplotlib
!pip install seaborn

import praw
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns

# Reddit API credentials
client_id = 'VPbj6VyUBsWTlTTgnHI_gA'
client_secret = 'Zydw7_cOkfXrfg104AxEXf0HIXobKw'
user_agent = 'someda'

# Connect to Reddit API
reddit = praw.Reddit(client_id=client_id, client_secret=client_secret, user_agent=user_agent)

# Function to collect recent posts
def collect_posts(keywords, limit=50):
    posts = []
    for keyword in keywords:
        subreddit = reddit.subreddit('all')
        subreddit_posts = subreddit.search(keyword, limit=limit)
        for post in subreddit_posts:
            posts.append([post.title, post.author.name, post.subreddit.display_name, post.created_utc])
    return posts

# Process the collected posts
def process_posts(posts):
    df = pd.DataFrame(posts, columns=['Title', 'Author', 'Subreddit', 'Timestamp'])
    df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')
    return df
default_keywords = ['telecom fraud','telecoms scam', 'phone fraud', 'billing fraud', 'identity theft', 'sim fraud', 'digital crime', 'identity theft']

custom_keywords = st.sidebar.text_input('Enter Custom Keywords (separated by comma)', '').split(',')
keywords = st.sidebar.multiselect('Select Keywords', default_keywords + custom_keywords, default=default_keywords)
dayz = st.sidebar.slider('Select Time Delta (in days)', 1, 50, 10,1)

"""Use Streamlit to create an interactive data visualization dashboard"""

# Display the streaming data in a table
st.table(streaming_data)

# Create a real-time line chart of the streaming data
chart_data = pd.DataFrame(np.random.randn(20, 3), columns=['a', 'b', 'c'])
st.line_chart(chart_data)

# Create a histogram of the streaming data
hist_values = np.histogram(streaming_data['value'], bins=20)[0]
st.bar_chart(hist_values)

# Plot the frequency of fraud mentions over time on a line chart


    
    df['Convert_UTC'] = pd.to_datetime(df['Date/Time'], unit='s')
    # Group the data by date and count the number of mentions
    mention_counts = df['Convert_UTC'].dt.date.value_counts().sort_index()

    fig,ax = plt.subplots(figsize=(14, 8))
    mention_counts.plot(kind='line')
    plt.title('Frequency of Fraud Mentions over Time')
    plt.xlabel('Date')
    plt.ylabel('Number of Mentions')
    plt.xticks(rotation=45)
    #plt.show()
    st.markdown('<div class="chart-container">', unsafe_allow_html=True)
    st.markdown('<h2 class="chart-title">Line chart of fraud mentions</h2>', unsafe_allow_html=True)
    st.pyplot(fig)
    st.markdown('</div>', unsafe_allow_html=True)

def analyze_data(df):
    st.subheader("Fraud Mentions by Subreddit")
    subreddit_counts = df['Subreddit'].value_counts().head(10)
    st.bar_chart(subreddit_counts)

    st.subheader("Fraud Mentions Over Time")
    daily_counts = df.set_index('Timestamp').resample('D').size()
    st.line_chart(daily_counts)

# Main function to run the Streamlit app
def main():
    keywords = ['telecom fraud','telecoms scam', 'phone fraud', 'billing fraud', 'identity theft', 'sim fraud', 'digital crime', 'identity theft']
    posts = collect_posts(keywords)
    df = process_posts(posts)
    st.title("Telecom Fraud Posts")
    st.dataframe(df)
    analyze_data(df)

if __name__ == '__main__':
    main()